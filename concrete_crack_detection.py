# -*- coding: utf-8 -*-
"""Concrete_crack_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tX_diwW0FoAaNxr6hIPAWhDaX9wiultm

# **Concrete Crack Detection Using Transfer Learning**

In this notebook, the model is trained for concrete crack detection via 
transfer learning. **VGG19** is used as the base model.

**Methodology of Transfer Learning**

1.   **Data preprocessing** - data preprocessing is carried out by splitting dataset into train_data, validation_data and test_data. Preprocess_input method by tensorflow also being used to ensure the input image data fit and usable to the pre-trained mmodel
2.   **Feature Extraction** - Feature extraction is carried out by freezing the entire base model and adding our own the classifier, dropout and output layer to the existing base model. The training will used the exsiting pre-trained weights.
3.   **Compile the model** - compile the built model
4.   **Implement Early Stopping** - this is to ensure the model is not overfitting
5.   **Fine-Tune Model** - Fine_tuning is method to increase performance even further or "fine-tunes" the weights of the top layer of the VGG19 model alongside the classifier added
6.   **Evaluate the model** - this is done by observing the model loss and accuracy, whether there is overfitting or underfitting 
7.   **Make predictions** - the test dataset is used to make prediction on the trained model
8.   **Save model** - If all circumtance is satisified and fullfilled, the model is saved for deployment

## Data preprocessing
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip -uq "/content/drive/MyDrive/Dataset.zip" -d "/content/sample_data"

# import necessary modules
import numpy as np
import pathlib
import matplotlib.pyplot as plt
import tensorflow as tf

file_path = r"/content/sample_data/Dataset"
data_dir = pathlib.Path(file_path)

# Split the dataset into train and validation data
SEED = 1234
BATCH_SIZE = 10
IMG_SIZE = (160,160)

train_data = tf.keras.utils.image_dataset_from_directory(data_dir,
                                                         validation_split = 0.2,
                                                         subset = 'training',
                                                         seed = SEED,
                                                         image_size = IMG_SIZE,
                                                         batch_size = BATCH_SIZE,
                                                         shuffle = True)

validation_data = tf.keras.utils.image_dataset_from_directory(data_dir,
                                                              validation_split = 0.2,
                                                              subset = 'validation',
                                                              seed = SEED,
                                                              image_size = IMG_SIZE,
                                                              batch_size = BATCH_SIZE,
                                                              shuffle = True)

# plot the image for viewing
class_names = train_data.class_names

plt.figure(figsize=(10,10))
for images, labels in train_data.take(1):
  for i in range(10):
    ax = plt.subplot(5,5,i+1)
    plt.imshow(images[1].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

# Now, we split further the validation data to test data for image prediction after model training
val_batches = tf.data.experimental.cardinality(validation_data)
test_data = validation_data.take(val_batches // 2)
validation_data = validation_data.skip(val_batches // 2)

print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_data))
print('Number of test batches: %d' % tf.data.experimental.cardinality(test_data))

# Check the splitted dataset
print(f"train_data : {len(train_data)}")
print(f"validation_data : {len(validation_data)}")
print(f"test_data : {len(test_data)}")

# Create prefetch dataset for better performance
AUTOTUNE = tf.data.AUTOTUNE

train_data = train_data.prefetch(buffer_size = AUTOTUNE)
validation_data = validation_data.prefetch(buffer_size = AUTOTUNE)
test_data = test_data.prefetch(buffer_size = AUTOTUNE)

# Data augmentation is applied to artificially introduce sample diversity
data_augmentation = tf.keras.Sequential(
    [tf.keras.layers.RandomFlip('horizontal'),
     tf.keras.layers.RandomRotation(0.2)
     ]
)

# plot the image for viewing
for images, labels in train_data.take(1):
  plt.figure(figsize=(10,10))
  first_image = images[0]
  for i in range(9):
    ax = plt.subplot(3,3,i+1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0]/255)
    plt.axis('off')

# Use the preprocess_input method to rescale the image to fit into the pre-trained model
preprocess_input = tf.keras.applications.vgg19.preprocess_input

"""## Feature Extractions"""

# Create the base model by calling out VGG19
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.VGG19(input_shape = IMG_SHAPE,
                                         include_top = False,
                                         weights = 'imagenet',)

# print out the base model summary
base_model.summary()

# Freeze the entire base_model
base_model.trainable = False
# print out the freezed base_model
base_model.summary()

# Add the classification layer using GlobalAveragePooling2D
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

# Add output layer
nClass = len(class_names)
prediction_layer = tf.keras.layers.Dense(nClass, activation = 'softmax')

# Now we can construct our own model based on base_model using API functional from tensorflow
# set an EarlyStopping to avoid overfitting
callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3)

# star building own model with input, base_model, classifier, dropout and output layer
inputs = tf.keras.Input(shape = (160,160, 3))
x = data_augmentation(inputs)
x = preprocess_input(x)
x = base_model(x, training = False)
x = global_average_layer(x)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = prediction_layer(x)
model = tf.keras.Model(inputs, outputs)

# compile the model
base_learning_rate = 0.0001
model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),
              loss = tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics = ['accuracy'])

# check the newly built model
model.summary()

tf.keras.utils.plot_model(model)

# Since this is pre-trained model, we can check the model performance before training
loss0, accuracy0 = model.evaluate(validation_data)

print("-------------------------------------Before Training--------------------------------------")
print("Loss", loss0)
print("Accuracy", accuracy0)

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard
from gc import callbacks
import datetime, os
logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

# we can start train the model
initial_epochs = 10
history = model.fit(train_data,
                    epochs = initial_epochs,
                    validation_data = validation_data,
                    callbacks = [tensorboard_callback, callback])

#tf.keras.backend.clear_session()

# Commented out IPython magic to ensure Python compatibility.
# View training accuracy and loss graph via tensorboard
# %tensorboard --logdir logs

# plot the graph
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8,8))
plt.subplot(2, 1, 1)
plt.plot(acc, label = 'Training Accuracy')
plt.plot(val_acc, label = 'Validation Accuracy')
plt.legend(loc = 'lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()), 1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label = 'Training Loss')
plt.plot(val_loss, label = 'Validation Loss')
plt.legend(loc = 'upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""## Fine-tuning Stage"""

# Perform FINE TUNING of the trained model
# In the first feature extraction training, the model was only trained a few layers on top of VGG19 base_model. The weights of the pretrained network were not updated during training
# Fine_tuning is method to increase performance even further or "fine-tunes" the weights of the top layer of the VGG19 model alongside the classifier added
# We need to unfreeze the top layers- pf the base model
base_model.trainable = True

# let's take a look at the model layers
print("Number of layers in the base model: ", len(base_model.layers))

# So, we are going to fine-tune 10 layers ahead
fine_tune_at = 10

# Freeze all the layer before "fine_tune_at" layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable = False

# compile the model again
# As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly.
model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),
              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),
              metrics = ['accuracy'])

# lets check the model again
model.summary()

tf.keras.utils.plot_model(model)

# Now, we resume the model trianing from the last epochs
fine_tune_epochs = 10
total_epochs = initial_epochs + fine_tune_epochs

# train the model again
histroy_fine_tune = model.fit(train_data,
                              epochs = total_epochs,
                              initial_epoch = history.epoch[-1],
                              validation_data = validation_data,
                              callbacks = [tensorboard_callback, callback])

# Commented out IPython magic to ensure Python compatibility.
# View training accuracy and loss graph via tensorboard
# %tensorboard --logdir logs

# Plot the feature_extraction + at_fine_tune graph
acc += histroy_fine_tune.history['accuracy']
val_acc += histroy_fine_tune.history['val_accuracy']

loss += histroy_fine_tune.history['loss']
val_loss += histroy_fine_tune.history['val_loss']

plt.figure(figsize=(10, 10))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.ylim([0.8, 1])
plt.plot([initial_epochs-1,initial_epochs-1],
          plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.ylim([0, 1.0])
plt.plot([initial_epochs-1,initial_epochs-1],
         plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.ylabel('Loss')
plt.show()

# Evaluate the model
print("-----------------------------------After Fine-tuning model..........................................")
model.evaluate(test_data)

# Now we can use the trained model to make prediction from test dataset
image_batch, label_batch = test_data.as_numpy_iterator().next()
predictions = model.predict_on_batch(image_batch)
class_predictions = np.argmax(predictions, axis=1)

# Plot the prediction image
plt.figure(figsize = (20,20))

for i in range(10):
  axs = plt.subplot(5,5,i+1)
  plt.imshow(image_batch[i].astype("uint8"))
  current_prediction = class_names[class_predictions[i]]
  current_label = class_names[label_batch[i]]
  plt.title(f"Prediction : {current_prediction} \n Actual : {current_label}")
  plt.axis("off")

"""## Save the model"""

# save the model at the apropriate location
model.save("/content/drive/MyDrive/concrete_crack_detection_model")